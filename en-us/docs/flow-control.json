{
  "filename": "flow-control.md",
  "__html": "<h1>Flow Control</h1>\n<h1>Introduction</h1>\n<p>Based on the runtime statistics collected in previous slots, FlowSlot will use pre-set rules to decide whether the incoming requests should be controlled.</p>\n<p><code>SphU.entry(resourceName)</code> will throw <code>FlowException</code> if any rule is triggered. You can customize your own logic by catching this exception.</p>\n<p>One resource can have multiple flow control rules. FlowSlot traverses these rules until one of them is triggered or all rules have been passed.</p>\n<p>A flow control rule consists of the following elements, and you can use a combination of different elements to cater for different flow control needs.</p>\n<ul>\n<li>resource：resource name</li>\n<li>count: thresholds of flow control</li>\n<li>grade: threshold type, can be QPS or thread number</li>\n<li>strategy: select flow control strategy based on calling trace (invocation chain)</li>\n<li>controlBehavior: effect of traffic shaping</li>\n</ul>\n<h1>Flow Control by Thread/QPS</h1>\n<h2>Metric Type</h2>\n<p>You can control either by <em>thread count</em> or <em>QPS</em>. It is defined by the <code>grade</code> field in <code>FlowRule</code>. Both concurrent thread count and request count are collected at runtime, and you can run the following command to view the statistics:</p>\n<pre><code class=\"language-shell\">curl http//localhost:8719/tree?type=root\n</code></pre>\n<p>The output is as follows:</p>\n<pre><code> idx id    thread pass  blocked   success total aRt   1m-pass   1m-block   1m-all   exception   \n2   abc647 0      460    46          46   1    27      630       276        897      0\n</code></pre>\n<ul>\n<li>thread: the number of threads which are currently processing the resource;</li>\n<li>pass: the count of incoming requests within one second;</li>\n<li>blocked: the count of requests blocked within one second;</li>\n<li>success: the count of the requests successfully processed within one second;</li>\n<li>RT: the average response time of the requests within a second;</li>\n<li>total: the sum of incoming requests and blocked requests within one second;</li>\n<li>1m-pass: the count of incoming requests within one minute;</li>\n<li>1m-block: the count of requests blocked within one minute;</li>\n<li>1m-all: the total of incoming and blocked requests within 1 minute;</li>\n<li>exception: the count of exceptions in one second.</li>\n</ul>\n<h3>Concurrent Thread count</h3>\n<p>This mode is usually used to protect threads from being occupied. If a resource takes a long time to finish, threads blocked in this resource will begin to be occupied. The longer the response takes, the more threads might be occupied.</p>\n<p>Besides thread count, there are 2 other ways to achieve this, thread pool or semaphore.</p>\n<ul>\n<li>Thread pool: Allocate a thread pool to handle these resources. When there is no more idle thread in the pool, the request is rejected without affecting other resources.</li>\n<li>Semaphore: Use semaphore to control the concurrent count of the threads.</li>\n</ul>\n<p>The benefit of using thread pools is that you can isolate business logic completely by pre-allocating thread pools. But it also brings us extra costs of context switch and additional threads. If the incoming request is already handled in a separated thread, for instance, a servlet request, it will almost double the thread count if using the thread pool mode.</p>\n<p>So we recommend to use concurrent thread count flow control, which represents lightweight semaphore isolation.</p>\n<h3>QPS</h3>\n<p>When QPS exceeds the threshold, we will take actions to control the incoming requests, and this can be done by configuring the <code>controlBehavior</code> field in <code>FlowRule</code>.</p>\n<p>1.　Immediately reject (<code>RuleConstant.CONTROL_BEHAVIOR_DEFAULT</code>)</p>\n<p>This is the default behavior. The exceeded requests are rejected immediately and the FlowException is thrown.</p>\n<p>2.　WarmUp（<code>RuleConstant.CONTROL_BEHAVIOR_WARM_UP</code>)</p>\n<p>If the usage of the system has been low for a while, but all of a sudden a large amount of requests comes in, the system might not be able to handle all these requests at once. However, if we steadily increase the incoming requests and allows the system to warm up, it may be able to handle all the requests eventually.</p>\n<p>This warm-up period can be configured by setting the <code>warmUpPeriodSec</code> field in <code>FlowRule</code>.</p>\n<p><img src=\"https://github.com/alibaba/Sentinel/wiki/image/warmup.gif\" alt=\"WarmUp\"></p>\n<p>3.Rate limiter (<code>RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER</code>)</p>\n<p>This strategy strictly controls the interval between requests. In other words, it allows requests to pass at a uniform rate.</p>\n<p><img src=\"https://github.com/alibaba/Sentinel/wiki/image/uniform-speed-queue.png\" alt=\"Uniform rate\"></p>\n<p>This strategy is an implement of <a href=\"https://en.wikipedia.org/wiki/Leaky_bucket\">leaky bucket</a>. It is used to handle requests at a stable rate and is often used to process burst requests instead of rejecting them. For instance, a sudden inflow of messages. When a large number of requests arrive at the same time, the system can handle all these incoming requests at a fixed rate.</p>\n<h1>Flow Control by Call Path</h1>\n<p>We use the NodeSelectorSlot to establish the paths of resources, and the ClusterNodeBuilderSlot to collect the caller's runtime data.</p>\n<h3>By caller</h3>\n<p>When calling <code>ContextUtil.enter(resourceName, origin)</code>, the parameter <code>origin</code> indicates the identity of the caller. <code>ClusetNodeBuilderSlot</code> will collect this info, and uses it to perform flow control.</p>\n<p>This information can be displayed by the following command:</p>\n<pre><code>id: nodeA\nidx origin  threadNum passedQps blockedQps totalQps aRt   1m-passed 1m-blocked 1m-total \n1   caller1 0         0         0          0        0     0         0          0        \n2   caller2 0         0         0          0        0     0         0          0        \n</code></pre>\n<p>The <code>origin</code> can be defined by the field <code>limitApp</code> in FlowRule. This field has the following values:</p>\n<ul>\n<li><code>default</code>: No specific caller. If the total value of this resource exceeds the threshold defined in this rule, the incoming request will be blocked.</li>\n<li><code>&lt;&lt;origin&gt;&gt;</code>: A specific caller has exceeded the threshold defined in the rule.</li>\n<li><code>other</code>: This rule applies to requests from a caller that is not defined explicitly in the <code>origin</code> field for this resource.</li>\n</ul>\n<h3>By entrance</h3>\n<p>The path is maintained in <code>NodeSelectorSlot</code>. For example, the resource nodes can come from either entrance1 or entrance2.</p>\n<pre><code>     \t          machine-root\n                    /       \\   \n                   /         \\\n             Entrance1     Entrance2\n                /             \\\n               /               \\\n      DefaultNode(nodeA)   DefaultNode(nodeA)\n</code></pre>\n<p>We can shape the flow by setting the field <code>strategy</code> to <code>RuleConstant.CHAIN</code>, and <code>ref_identity</code> to a specified entrance.</p>\n<h3>By related resource</h3>\n<p>For instance, two resources will access the same database record. ResourceA will read records from the database, resourceB will write records to the database. The frequency of ResourceA accessing the database depends on ResourceB. We can achieve this by configuring a rule for ResourceA with the value of the <code>strategy</code> field as <code>RuleConstant.RELATE</code>, and the value of <code>ref_identity</code> as ResourceB.</p>\n",
  "link": "/en-us/docs/flow-control.html",
  "meta": {}
}