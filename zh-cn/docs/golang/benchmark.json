{
  "filename": "Benchmark.md",
  "__html": "<h1>Benchmark</h1>\n<h2>测试环境</h2>\n<p>CPU：Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz (32 Cores)\nOS：Red Hat 4.8.2-16\nGolang version: 1.14.3</p>\n<h2>吞吐量对比</h2>\n<p>测试单协程/并发模式下接入 Sentinel 与不接入 Sentinel 吞吐量的对比。我们通过执行一些 CPU 密集型操作（小数组排序）来模拟不同 QPS 下的情况。测试例子参考：<a href=\"https://github.com/louyuting/sentinel-golang/tree/add_benchmark/tests\">Benchmark</a></p>\n<h3>单协程吞吐量</h3>\n<pre><code>Benchmark_Single_Directly_50    \t 4081059\t       882 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_50    \t 4075447\t       886 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_50    \t 4065984\t       884 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_50   \t 2508170\t      1434 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_50   \t 2508332\t      1435 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_50   \t 2506646\t      1437 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_100   \t 1504512\t      2391 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_100   \t 1506342\t      2393 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_100   \t 1500378\t      2393 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_100  \t 1224729\t      2937 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_100  \t 1225106\t      3257 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_100  \t 1168003\t      2935 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_200   \t  613916\t      5899 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_200   \t  609230\t      5915 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_200   \t  612487\t      5910 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_200  \t  556461\t      6473 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_200  \t  561085\t      6477 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_200  \t  550544\t      6461 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_500   \t  190442\t     18859 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_500   \t  185095\t     18902 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_500   \t  191236\t     18889 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_500  \t  185674\t     19426 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_500  \t  185353\t     19444 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_500  \t  185371\t     19487 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_1000  \t   86101\t     41642 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_1000  \t   86492\t     41760 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_1000  \t   86415\t     41769 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_1000 \t   83931\t     42339 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_1000 \t   84270\t     42321 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_1000 \t   85328\t     42420 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_2000  \t   39504\t     90540 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_2000  \t   39612\t     90218 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_Directly_2000  \t   39786\t     90401 ns/op\t      32 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_2000 \t   39234\t     91519 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_2000 \t   39418\t     91123 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_2000 \t   39360\t     91208 ns/op\t     128 B/op\t       4 allocs/op\nBenchmark_Single_Directly_4000  \t   18218\t    197592 ns/op\t      33 B/op\t       1 allocs/op\nBenchmark_Single_Directly_4000  \t   18194\t    197011 ns/op\t      33 B/op\t       1 allocs/op\nBenchmark_Single_Directly_4000  \t   18213\t    197554 ns/op\t      33 B/op\t       1 allocs/op\nBenchmark_Single_StatEntry_4000 \t   18105\t    198295 ns/op\t     130 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_4000 \t   18162\t    198432 ns/op\t     130 B/op\t       4 allocs/op\nBenchmark_Single_StatEntry_4000 \t   18162\t    198686 ns/op\t     129 B/op\t       4 allocs/op\n</code></pre>\n<p>这里取三组数据的中位值：</p>\n<table>\n<thead>\n<tr>\n<th>数组长度</th>\n<th>Baseline(QPS)</th>\n<th>With Sentinel(QPS)</th>\n<th>性能损耗</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>50</td>\n<td>1131221</td>\n<td>696864</td>\n<td>38.4%</td>\n</tr>\n<tr>\n<td>100</td>\n<td>417885</td>\n<td>340483</td>\n<td>18.5%</td>\n</tr>\n<tr>\n<td>200</td>\n<td>169204</td>\n<td>154487</td>\n<td>8.7%</td>\n</tr>\n<tr>\n<td>500</td>\n<td>52940</td>\n<td>51429</td>\n<td>2.9%</td>\n</tr>\n<tr>\n<td>1000</td>\n<td>23946</td>\n<td>23618</td>\n<td>1.4%</td>\n</tr>\n<tr>\n<td>2000</td>\n<td>11061</td>\n<td>10963</td>\n<td>0.9%</td>\n</tr>\n<tr>\n<td>4000</td>\n<td>5061</td>\n<td>5039</td>\n<td>0.4%</td>\n</tr>\n</tbody>\n</table>\n<p>可以看到在单机 QPS 非常大的时候（16W+），Sentinel 带来的性能损耗会比较大。这种情况业务逻辑本身的耗时非常小，而 Sentinel 一系列的统计、检查操作会消耗一定的时间。常见的场景有缓存读取操作。</p>\n<p>而单机 QPS 在 6W 以下的时候，Sentinel 的性能损耗就比较小了，对大多数场景来说都适用。</p>\n<h2>多协程影响</h2>\n<p>测试排序数组长度是200时候，并发4/8/16/32/32+协程并发下的性能：</p>\n<table>\n<thead>\n<tr>\n<th>并发数</th>\n<th>With Sentinel(QPS)</th>\n<th>性能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>154487</td>\n<td>100%</td>\n</tr>\n<tr>\n<td>4</td>\n<td>586510</td>\n<td>379%</td>\n</tr>\n<tr>\n<td>8</td>\n<td>685871</td>\n<td>443%</td>\n</tr>\n<tr>\n<td>16</td>\n<td>1324503</td>\n<td>857%</td>\n</tr>\n<tr>\n<td>32</td>\n<td>1449275</td>\n<td>938%</td>\n</tr>\n</tbody>\n</table>\n<p>32并发以上基本没有提升了。</p>\n<h2>内存占用情况</h2>\n<p>测试场景：6000 个资源循环跑（即单机的极端场景，目前最多支持 6000 个 entry）</p>\n<ul>\n<li>单协程不断循环运行：内存占用约 30 MB</li>\n<li>8个协程不断循环运行：内存占用约 36 MB</li>\n</ul>\n"
}